{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install scholarly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxzOGrZBPWr_",
        "outputId": "3de2cff5-3866-483f-a117-f494c91ad974"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scholarly\n",
            "  Downloading scholarly-1.7.11-py3-none-any.whl (39 kB)\n",
            "Collecting arrow (from scholarly)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.12.3)\n",
            "Collecting bibtexparser (from scholarly)\n",
            "  Downloading bibtexparser-1.4.1.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated (from scholarly)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting fake-useragent (from scholarly)\n",
            "  Downloading fake_useragent-1.4.0-py3-none-any.whl (15 kB)\n",
            "Collecting free-proxy (from scholarly)\n",
            "  Downloading free_proxy-1.1.1.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx (from scholarly)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from scholarly)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from scholarly) (2.31.0)\n",
            "Collecting selenium (from scholarly)\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-rtd-theme (from scholarly)\n",
            "  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->scholarly) (2.8.2)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->scholarly)\n",
            "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->scholarly) (2.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from bibtexparser->scholarly) (3.1.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scholarly) (1.14.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from free-proxy->scholarly) (4.9.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->scholarly)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->scholarly)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (2.0.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (1.7.1)\n",
            "Collecting trio~=0.17 (from selenium->scholarly)\n",
            "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium->scholarly)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: sphinx<8,>=5 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.21 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (0.18.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->scholarly)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.6)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.1.10)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.7)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (3.1.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.14.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (23.2)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium->scholarly)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->scholarly)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.1.5)\n",
            "Building wheels for collected packages: bibtexparser, free-proxy\n",
            "  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bibtexparser: filename=bibtexparser-1.4.1-py3-none-any.whl size=43252 sha256=5eb3fd794fe9d1c0e5ef88c71936f229f88e83bec5aa1f68d421a40cf735b517\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c6/c3/56e639fab68d1fdbf13ea147636d9795ccdbd3c1d3178d1332\n",
            "  Building wheel for free-proxy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for free-proxy: filename=free_proxy-1.1.1-py3-none-any.whl size=5637 sha256=1b5e06870a781526728b599b8461bec82ed41c04b0886cc91b79e5a37e575709\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/96/c7/5a434714fff4fea9a59075428b142626e0a74f8c3bf90a50d0\n",
            "Successfully built bibtexparser free-proxy\n",
            "Installing collected packages: fake-useragent, types-python-dateutil, python-dotenv, outcome, h11, deprecated, bibtexparser, wsproto, trio, httpcore, free-proxy, arrow, trio-websocket, sphinxcontrib-jquery, httpx, sphinx-rtd-theme, selenium, scholarly\n",
            "Successfully installed arrow-1.3.0 bibtexparser-1.4.1 deprecated-1.2.14 fake-useragent-1.4.0 free-proxy-1.1.1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 outcome-1.3.0.post0 python-dotenv-1.0.1 scholarly-1.7.11 selenium-4.18.1 sphinx-rtd-theme-2.0.0 sphinxcontrib-jquery-4.1 trio-0.24.0 trio-websocket-0.11.1 types-python-dateutil-2.8.19.20240106 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w4_jzITPJ7G",
        "outputId": "c7fde820-abc0-4b18-ee40-d53d16687733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic/model: machine learning\n",
            "Enter the number of papers to retrieve: 5\n",
            "Scraped 5 paper titles and links. Saved to machine learning_research_papers.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from scholarly import scholarly\n",
        "\n",
        "def scrape_paper_info(topic, num_results=10):\n",
        "    try:\n",
        "        search_query = scholarly.search_pubs(topic)\n",
        "        papers_info = []\n",
        "\n",
        "        # Retrieve the specified number of paper titles and links\n",
        "        for i in range(num_results):\n",
        "            paper = next(search_query)\n",
        "            title = paper['bib']['title']\n",
        "            link = paper['pub_url']\n",
        "            papers_info.append((title, link))\n",
        "\n",
        "        return papers_info\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to retrieve data from Google Scholar: {e}\")\n",
        "        return []\n",
        "\n",
        "def save_to_csv(papers_info, filename):\n",
        "    # Write the titles and links to a CSV file\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Title', 'Link']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for title, link in papers_info:\n",
        "            writer.writerow({'Title': title, 'Link': link})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    topic = input(\"Enter the topic/model: \")\n",
        "    num_results = int(input(\"Enter the number of papers to retrieve: \"))\n",
        "\n",
        "    papers_info = scrape_paper_info(topic, num_results)\n",
        "    if papers_info:\n",
        "        save_to_csv(papers_info, f\"{topic}_research_papers.csv\")\n",
        "        print(f\"Scraped {len(papers_info)} paper titles and links. Saved to {topic}_research_papers.csv\")\n",
        "    else:\n",
        "        print(\"No paper titles and links were scraped.\")\n"
      ]
    }
  ]
}